{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import random\n",
    "import string\n",
    "import subprocess\n",
    "from typing import List, Annotated\n",
    "from typing_extensions import TypedDict\n",
    "\n",
    "from langchain_openai import ChatOpenAI\n",
    "from langchain_core.tools import tool\n",
    "from langchain_core.messages import AIMessage\n",
    "from langgraph.prebuilt import ToolNode\n",
    "from langgraph.graph import StateGraph, MessagesState, START, END"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The following code shows an example of building a custom LLM-based assistant. The LLM is a 8B 6-bit-quantized Llama 3 (https://huggingface.co/meta-llama/Llama-3.1-8B-Instruct), deployed on local LangCPP server. The main goal is to achieve complex behaviors by just using a local LLM, which can fit inside a notebook GPU (at most 8 GB memory)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The capital of France is Paris.\n"
     ]
    }
   ],
   "source": [
    "llm = ChatOpenAI(\n",
    "    base_url=\"http://localhost:8000/v1\",\n",
    "    api_key=\"sk-fake-key\",  # Not needed but required for OpenAI compatibility,\n",
    "    temperature=0.\n",
    ")\n",
    "\n",
    "response = llm.invoke(\"What is the capital of france?\")\n",
    "print(response.content)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Langgraph agent"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's use a custom LangGraph agent for the assistant. Our selected task for the bot is a filesystem assistant, where the AI can observe some local files and folder and decide to write some contents (attention: not safe for the systen, just for demonstration purpose). Let's implement some tools for the task, and check some basic queries:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "WS_PATH = \"workspace\"\n",
    "\n",
    "@tool\n",
    "def list_directory(path: str) -> List[str]:\n",
    "    \"\"\"List the child nodes inside a directory.\"\"\"\n",
    "    try:\n",
    "        if path[0] == '/':\n",
    "            path = path[1:]\n",
    "        return os.listdir(os.path.join(WS_PATH, path))\n",
    "    except Exception as e:\n",
    "        return [f\"Error: {str(e)}, {os.path.join(WS_PATH, path)}\"]\n",
    "\n",
    "@tool\n",
    "def read_file(path: str) -> str:\n",
    "    \"\"\"Read the content of a file.\"\"\"\n",
    "    if path[0] == '/':\n",
    "        path = path[1:]\n",
    "    filepath = os.path.join(WS_PATH, path)\n",
    "    if not os.path.exists(filepath):\n",
    "        return \"Error: File does not exist\"\n",
    "    try:\n",
    "        with open(filepath, \"r\", encoding=\"utf-8\") as file:\n",
    "            return file.read()\n",
    "    except Exception as e:\n",
    "        return f\"Error: {str(e)}, {os.path.join(WS_PATH, path)}\"\n",
    "\n",
    "@tool\n",
    "def write_file(path: str, content: str) -> str:\n",
    "    \"\"\"Write some new content into a file.\"\"\"\n",
    "    if path[0] == '/':\n",
    "        path = path[1:]\n",
    "    filepath = os.path.join(WS_PATH, path)\n",
    "    try:\n",
    "        print(f\"Writing to {filepath}\")\n",
    "        # with open(filepath, \"w\", encoding=\"utf-8\") as file:\n",
    "        #     file.write(content)\n",
    "        return \"Success: File updated.\"\n",
    "    except Exception as e:\n",
    "        return f\"Error: {str(e)}, {os.path.join(WS_PATH, path)}\"\n",
    "\n",
    "@tool\n",
    "def execute_main(path: str) -> str:\n",
    "    \"\"\"Executes a Python file.\"\"\"\n",
    "    if path[0] == '/':\n",
    "        path = path[1:]\n",
    "    filepath = os.path.join(WS_PATH, path)\n",
    "    if not os.path.exists(filepath):\n",
    "        return \"Error: File does not exist.\"\n",
    "    try:\n",
    "        result = subprocess.run([\"python\", filepath], capture_output=True, text=True)\n",
    "        return result.stdout if result.returncode == 0 else result.stderr\n",
    "    except Exception as e:\n",
    "        return f\"Error: {str(e)}, {os.path.join(WS_PATH, path)}\"\n",
    "\n",
    "tools = [list_directory, read_file, write_file, execute_main]\n",
    "tool_node = ToolNode(tools)\n",
    "\n",
    "llm_with_tools = llm.bind_tools(tools)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\rocca\\AppData\\Local\\Temp\\ipykernel_12444\\2723539149.py:1: LangChainDeprecationWarning: The method `BaseTool.__call__` was deprecated in langchain-core 0.1.47 and will be removed in 1.0. Use :meth:`~invoke` instead.\n",
      "  read_file('dummy.txt')\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'Auisa&8sva72'"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "read_file('dummy.txt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'messages': [ToolMessage(content='Auisa&8sva72', name='read_file', tool_call_id='2')]}"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "message_with_single_tool_call = AIMessage(\n",
    "    content=\"\",\n",
    "    tool_calls=[\n",
    "        {\n",
    "            \"name\": \"read_file\",\n",
    "            \"args\": {\"path\": \"dummy.txt\"},\n",
    "            \"id\": \"2\",\n",
    "            \"type\": \"tool_call\",\n",
    "        }\n",
    "    ],\n",
    ")\n",
    "\n",
    "tool_node.invoke({\"messages\": [message_with_single_tool_call]})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "llm_with_tools = llm.bind_tools(tools)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'name': 'read_file',\n",
       "  'args': {'path': 'dummy.txt'},\n",
       "  'id': '',\n",
       "  'type': 'tool_call'}]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "llm_with_tools.invoke(\"Read the content of the file 'dummy.txt'\").tool_calls"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Our goal is to be able to submit complex requests to the assistant, which could require some structured reasoning and tool usages. Therefore we will adopt a planner-based cognitive architecture for the bot:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def gen_rand_id(length):\n",
    "    letters = string.ascii_letters + string.digits\n",
    "    return ''.join(random.choice(letters) for _ in range(length))\n",
    "\n",
    "\n",
    "\n",
    "def route_tools(state: MessagesState):\n",
    "    messages = state[\"messages\"]\n",
    "    last_message = messages[-1]\n",
    "\n",
    "    if hasattr(last_message, \"tool_calls\") and len(last_message.tool_calls) > 0:\n",
    "        return \"tools\"\n",
    "    return END\n",
    "\n",
    "\n",
    "def call_tool(state: MessagesState):\n",
    "    messages = state[\"messages\"]\n",
    "    response = llm_with_tools.invoke(messages)\n",
    "    for tool_call in response.tool_calls:\n",
    "        tool_call['id'] = gen_rand_id(16)\n",
    "    return {\"messages\": [response]}\n",
    "\n",
    "\n",
    "workflow = StateGraph(MessagesState)\n",
    "\n",
    "workflow.add_node(\"llm\", call_tool)\n",
    "workflow.add_node(\"tools\", tool_node)\n",
    "\n",
    "workflow.add_edge(START, \"llm\")\n",
    "workflow.add_conditional_edges(\"llm\", route_tools, [\"tools\", END])\n",
    "workflow.add_edge(\"tools\", \"llm\")\n",
    "\n",
    "app = workflow.compile()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<IPython.core.display.Image object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from IPython.display import Image, display\n",
    "try:\n",
    "    display(Image(app.get_graph().draw_mermaid_png()))\n",
    "except Exception:\n",
    "    # This requires some extra dependencies and is optional\n",
    "    pass"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's check the behavior for more complex queries:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================================\u001b[1m Human Message \u001b[0m=================================\n",
      "\n",
      "What is the content of the file at '/dummy.txt'?\n",
      "==================================\u001b[1m Ai Message \u001b[0m==================================\n",
      "Tool Calls:\n",
      "  read_file (F0buA8pkQ24A2pHP)\n",
      " Call ID: F0buA8pkQ24A2pHP\n",
      "  Args:\n",
      "    path: /dummy.txt\n",
      "=================================\u001b[1m Tool Message \u001b[0m=================================\n",
      "Name: read_file\n",
      "\n",
      "Auisa&8sva72\n",
      "==================================\u001b[1m Ai Message \u001b[0m==================================\n",
      "\n",
      "The content of the file at '/dummy.txt' is 'Auisa&8sva72'.\n"
     ]
    }
   ],
   "source": [
    "for chunk in app.stream(\n",
    "    {\"messages\": [(\"system\", \"Use your tools to answer the user query.\"),\n",
    "                  (\"human\", \"What is the content of the file at '/dummy.txt'?\")]}, stream_mode=\"values\"\n",
    "):\n",
    "    chunk[\"messages\"][-1].pretty_print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================================\u001b[1m Human Message \u001b[0m=================================\n",
      "\n",
      "What is the content of the directory at '/subdir'?\n",
      "==================================\u001b[1m Ai Message \u001b[0m==================================\n",
      "Tool Calls:\n",
      "  list_directory (tUqK8681AnembJuo)\n",
      " Call ID: tUqK8681AnembJuo\n",
      "  Args:\n",
      "    path: /subdir\n",
      "=================================\u001b[1m Tool Message \u001b[0m=================================\n",
      "Name: list_directory\n",
      "\n",
      "[\"dummy2.txt\", \"dummy3.txt\", \"subdir2\"]\n",
      "==================================\u001b[1m Ai Message \u001b[0m==================================\n",
      "\n",
      "The directory at '/subdir' contains the following items: \n",
      "1. dummy2.txt\n",
      "2. dummy3.txt\n",
      "3. subdir2\n"
     ]
    }
   ],
   "source": [
    "for chunk in app.stream(\n",
    "    {\"messages\": [(\"system\", \"Use your tools to answer the user query.\"),\n",
    "                  (\"human\", \"What is the content of the directory at '/subdir'?\")]}, stream_mode=\"values\"\n",
    "):\n",
    "    chunk[\"messages\"][-1].pretty_print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================================\u001b[1m Human Message \u001b[0m=================================\n",
      "\n",
      "What is the content of one random file inside the directory at '/subdir'?\n",
      "==================================\u001b[1m Ai Message \u001b[0m==================================\n",
      "Tool Calls:\n",
      "  list_directory (iiDBJWP37YWAur8P)\n",
      " Call ID: iiDBJWP37YWAur8P\n",
      "  Args:\n",
      "    path: /subdir\n",
      "=================================\u001b[1m Tool Message \u001b[0m=================================\n",
      "Name: list_directory\n",
      "\n",
      "[\"dummy2.txt\", \"dummy3.txt\", \"subdir2\"]\n",
      "==================================\u001b[1m Ai Message \u001b[0m==================================\n",
      "Tool Calls:\n",
      "  read_file (W356ZJtuNbRytNbY)\n",
      " Call ID: W356ZJtuNbRytNbY\n",
      "  Args:\n",
      "    path: /subdir/dummy2.txt\n",
      "=================================\u001b[1m Tool Message \u001b[0m=================================\n",
      "Name: read_file\n",
      "\n",
      "AAABDISFGGD\n",
      "==================================\u001b[1m Ai Message \u001b[0m==================================\n",
      "\n",
      "The content of the file 'dummy2.txt' inside the directory '/subdir' is 'AAABDISFGGD'.\n"
     ]
    }
   ],
   "source": [
    "for chunk in app.stream(\n",
    "    {\"messages\": [(\"system\", \"Use your tools to answer the user query.\"),\n",
    "                  (\"human\", \"What is the content of one random file inside the directory at '/subdir'?\")]}, stream_mode=\"values\"\n",
    "):\n",
    "    chunk[\"messages\"][-1].pretty_print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================================\u001b[1m Human Message \u001b[0m=================================\n",
      "\n",
      "Write the content of 'dummy.txt' inside the file at 'subdir/dummy2.txt'. What was the written value?\n",
      "==================================\u001b[1m Ai Message \u001b[0m==================================\n",
      "Tool Calls:\n",
      "  read_file (t8mk5EpxQSrcnXxl)\n",
      " Call ID: t8mk5EpxQSrcnXxl\n",
      "  Args:\n",
      "    path: dummy.txt\n",
      "=================================\u001b[1m Tool Message \u001b[0m=================================\n",
      "Name: read_file\n",
      "\n",
      "Auisa&8sva72\n",
      "==================================\u001b[1m Ai Message \u001b[0m==================================\n",
      "Tool Calls:\n",
      "  write_file (YI6Up3mRPjMXY8w1)\n",
      " Call ID: YI6Up3mRPjMXY8w1\n",
      "  Args:\n",
      "    path: subdir/dummy2.txt\n",
      "    content: Auisa&8sva72\n",
      "Writing to workspace\\subdir/dummy2.txt\n",
      "=================================\u001b[1m Tool Message \u001b[0m=================================\n",
      "Name: write_file\n",
      "\n",
      "Success: File updated.\n",
      "==================================\u001b[1m Ai Message \u001b[0m==================================\n",
      "\n",
      "The content of 'dummy.txt' has been successfully written into 'subdir/dummy2.txt'. The written value is 'Auisa&8sva72'.\n"
     ]
    }
   ],
   "source": [
    "for chunk in app.stream(\n",
    "    {\"messages\": [(\"system\", \"Use your tools to answer the user query.\"),\n",
    "                  (\"human\", \"Write the content of 'dummy.txt' inside the file at 'subdir/dummy2.txt'. What was the written value?\")]}, stream_mode=\"values\"\n",
    "):\n",
    "    chunk[\"messages\"][-1].pretty_print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================================\u001b[1m Human Message \u001b[0m=================================\n",
      "\n",
      "Write the content of 'dummy.txt' inside the file at 'subdir/dummy2.txt'. Then write the content of 'subdir/dummy3.txt' into 'dummy.txt'\n",
      "==================================\u001b[1m Ai Message \u001b[0m==================================\n",
      "Tool Calls:\n",
      "  read_file (N0O5kvZ2y4l4GJlP)\n",
      " Call ID: N0O5kvZ2y4l4GJlP\n",
      "  Args:\n",
      "    path: dummy.txt\n",
      "=================================\u001b[1m Tool Message \u001b[0m=================================\n",
      "Name: read_file\n",
      "\n",
      "Auisa&8sva72\n",
      "==================================\u001b[1m Ai Message \u001b[0m==================================\n",
      "Tool Calls:\n",
      "  write_file (Mdb37IF0Kuy954jU)\n",
      " Call ID: Mdb37IF0Kuy954jU\n",
      "  Args:\n",
      "    path: subdir/dummy2.txt\n",
      "    content: Auisa&8sva72\n",
      "Writing to workspace\\subdir/dummy2.txt\n",
      "=================================\u001b[1m Tool Message \u001b[0m=================================\n",
      "Name: write_file\n",
      "\n",
      "Success: File updated.\n",
      "==================================\u001b[1m Ai Message \u001b[0m==================================\n",
      "Tool Calls:\n",
      "  read_file (5sJY6Vs5gcM3oXpf)\n",
      " Call ID: 5sJY6Vs5gcM3oXpf\n",
      "  Args:\n",
      "    path: subdir/dummy3.txt\n",
      "=================================\u001b[1m Tool Message \u001b[0m=================================\n",
      "Name: read_file\n",
      "\n",
      "content3\n",
      "==================================\u001b[1m Ai Message \u001b[0m==================================\n",
      "Tool Calls:\n",
      "  write_file (G3cpJY6h4o456Wxr)\n",
      " Call ID: G3cpJY6h4o456Wxr\n",
      "  Args:\n",
      "    path: dummy.txt\n",
      "    content: content3\n",
      "Writing to workspace\\dummy.txt\n",
      "=================================\u001b[1m Tool Message \u001b[0m=================================\n",
      "Name: write_file\n",
      "\n",
      "Success: File updated.\n",
      "==================================\u001b[1m Ai Message \u001b[0m==================================\n",
      "\n",
      "The content of 'dummy.txt' has been updated to 'content3' and 'subdir/dummy2.txt' has been updated to 'Auisa&8sva72'.\n"
     ]
    }
   ],
   "source": [
    "for chunk in app.stream(\n",
    "    {\"messages\": [(\"system\", \"Use your tools to answer the user query.\"),\n",
    "                  (\"human\", \"Write the content of 'dummy.txt' inside the file at 'subdir/dummy2.txt'. Then write the content of 'subdir/dummy3.txt' into 'dummy.txt'\")]}, stream_mode=\"values\"\n",
    "):\n",
    "    chunk[\"messages\"][-1].pretty_print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Please note that the presented architecture is just a baseline example for exploring the capabilities of the described architecture. In order to have a more reliable response for more complex queries, the cognitive system can be developed even more. A context-extended model can also be used to improve longer planning of the current agent, such as the Qwen2.5-7B-Instruct-1M-Q6_K model."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "notebook1-py10",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
